{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import sys\n",
    "import natsort\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import util, measure\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.morphology import closing,  disk, dilation, erosion, ball\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.transform import rescale\n",
    "\n",
    "import napari\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "import tifffile\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE THIS - SOMETIMES THE DECONVOLUTION RETURNS IMAGES WITH PIXEL VALUES ALL OVER THE PLACE, SO THIS CONVERTS EVERY IMAGE TO HAVE PIXEL VALUES BETWEEN 0 AND 255\n",
    "def convert(img, target_type_min, target_type_max, target_type):\n",
    "    \"\"\"\n",
    "    Converts an image to a specified data type while scaling its intensity values.\n",
    "\n",
    "    This function rescales the intensity values of an image from its original range \n",
    "    to a new target range specified by `target_type_min` and `target_type_max`, and \n",
    "    then converts it to the desired data type.\n",
    "\n",
    "    This step is required as deconvolved images are not always scaled 0->255! \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : numpy.ndarray\n",
    "        The input image array to be converted.\n",
    "    target_type_min : int or float\n",
    "        The minimum value of the target intensity range.\n",
    "    target_type_max : int or float\n",
    "        The maximum value of the target intensity range.\n",
    "    target_type : numpy.dtype\n",
    "        The desired data type of the output image (e.g., np.uint8, np.float32).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    new_img : numpy.ndarray\n",
    "        The rescaled image with values mapped to the new intensity range and converted \n",
    "        to the specified data type.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function performs a linear transformation to scale pixel values.\n",
    "    - It ensures that the output values are properly mapped between `target_type_min` and \n",
    "      `target_type_max`.\n",
    "    \"\"\"\n",
    "    imin = img.min()\n",
    "    imax = img.max()\n",
    "\n",
    "    a = (target_type_max - target_type_min) / (imax - imin)\n",
    "    b = target_type_max - a * imax\n",
    "    new_img = (a * img + b).astype(target_type)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE THIS - EXTRACTS TIF SIZE FROM IMAGE METADATA\n",
    "def pixel_size(tif_path):\n",
    "    \"\"\"\n",
    "    Extracts the pixel size (spacing) in microns from a TIFF image.\n",
    "\n",
    "    This function reads TIFF metadata to determine the pixel spacing in the x, y, and z \n",
    "    dimensions, returning them as a list.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_path : str\n",
    "        Path to the TIFF file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    original_spacing : list of float\n",
    "        A list containing the pixel sizes in microns: [x_pixel_size_um, y_pixel_size_um, z_pixel_size_um].\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The x and y resolutions are extracted from the TIFF XResolution and YResolution tags.\n",
    "    - The z-spacing is inferred from the `IJMetadata` tag if available; otherwise, it falls back to \n",
    "      the `ImageDescription` tag.\n",
    "    - Assumes the metadata is formatted in a way compatible with ImageJ or similar software.\n",
    "    \"\"\"\n",
    "    with tifffile.TiffFile(tif_path) as tif:\n",
    "        tif_tags = {}\n",
    "        for tag in tif.pages[0].tags.values():\n",
    "            name, value = tag.name, tag.value\n",
    "            tif_tags[name] = value\n",
    "\n",
    "        x_pixel_size_um = 1/((tif_tags[\"XResolution\"])[0]/(tif_tags[\"XResolution\"][1]))\n",
    "        y_pixel_size_um = 1/((tif_tags[\"YResolution\"])[0]/(tif_tags[\"YResolution\"][1]))\n",
    "        try:\n",
    "            z_pixel_size_um = float(str(tif_tags[\"IJMetadata\"]).split(\"nscales=\")[1].split(\",\")[2].split(\"\\\\nunit\")[0])\n",
    "        except:\n",
    "            z_pixel_size_um = (float(str(tif_tags[\"ImageDescription\"]).split(\"spacing=\")[1].split(\"loop\")[0]))\n",
    "       \n",
    "    original_spacing = [x_pixel_size_um,y_pixel_size_um,z_pixel_size_um]\n",
    "    return original_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(path, z_size = 6.0800000, x_y_size = 0.1700744):\n",
    "    \"\"\"\n",
    "    Load and segment 3D or 4D label images, applying isotropic rescaling and nuclear seed-based watershed segmentation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Path to the input image file (3D/4D grayscale label image) to be segmented. The image is assumed to have time as the first axis if 4D.\n",
    "    z_size : float, optional\n",
    "        The physical step size in the z-direction (µm) of the image stack. Default is 6.08 µm.\n",
    "    x_y_size : float, optional\n",
    "        The physical pixel size in the x and y directions (µm). Default is 0.1700744 µm.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    timelapse_labels : np.ndarray\n",
    "        A 4D label array of shape (T, Z, Y, X), where each timepoint has been segmented using a seeded watershed approach.\n",
    "        Labels below the estimated volume of a 2 µm radius nucleus are excluded.\n",
    "\n",
    "    Method:\n",
    "    -------\n",
    "    1. Rescale the anisotropic stack to approach isotropic resolution in Z-Y-X (time unchanged).\n",
    "    2. Apply Gaussian smoothing and Otsu thresholding to segment foreground regions.\n",
    "    3. For each timepoint:\n",
    "        a. Compute a distance transform on an eroded binary mask.\n",
    "        b. Identify peak seed points for watershed segmentation using local maxima spaced ~4 µm apart.\n",
    "        c. Perform marker-controlled watershed to segment candidate nuclei.\n",
    "        d. Filter small regions below the estimated volume of a 2 µm radius sphere.\n",
    "    4. Return the cleaned label array for all timepoints.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The physical voxel size is used to estimate a volume threshold for filtering small objects.\n",
    "    - You can modify the `scale_value` to control isotropy tradeoffs (default is 0.5). Reduce if you have less compute power and vice versa\n",
    "    - Output labels are returned as a NumPy array with time along the first axis.\n",
    "\n",
    "    \"\"\"\n",
    "    image = convert(imread(path), 0,255, np.uint8)\n",
    "    scale_change = z_size / x_y_size #how much bigger the z step is than x,y\n",
    "    scale_value = 0.5\n",
    "    new_pixel_size = (1/scale_value) * x_y_size\n",
    "\n",
    "    #########CREATE LABELS\n",
    "    rescaled_image = rescale(scale = (1,scale_value*scale_change, scale_value, scale_value), image=(image ), anti_aliasing = False)\n",
    "    rescaled_image = gaussian(rescaled_image, sigma = 2)\n",
    "    thresh = threshold_otsu(rescaled_image)\n",
    "    rescaled_image = rescaled_image > thresh\n",
    "\n",
    "    all_output_labels = []\n",
    "    for t in range(rescaled_image.shape[0]):\n",
    "        single_time = rescaled_image[t,:,:]\n",
    "        distances = ndi.distance_transform_edt(erosion(single_time, ball(3)))\n",
    "        coordinates = peak_local_max(distances, min_distance = int(20)) ####seed points at least 4um apart\n",
    "        marker_locations = coordinates.data\n",
    "        markers = np.zeros(single_time.shape, dtype=np.uint32)\n",
    "        marker_indices = tuple(np.round(marker_locations).astype(int).T)\n",
    "        markers[marker_indices] = np.arange(len(marker_locations)) + 1\n",
    "        markers_big = dilation(markers, ball(2))\n",
    "        segmented = watershed(-distances, markers_big, mask=single_time)\n",
    "        table = regionprops_table(segmented, properties=('label', 'area'),)\n",
    "        volume_threshold = (4/3)*np.pi * (4/new_pixel_size)**2     # radius 2um nucleus\n",
    "        condition = (table['area'] >= volume_threshold)\n",
    "        input_labels = table['label']\n",
    "        output_labels = input_labels * condition\n",
    "        output_labels = util.map_array(segmented, input_labels, output_labels)\n",
    "        all_output_labels.append(output_labels)\n",
    "    timelapse_labels = np.stack(all_output_labels, axis=0)\n",
    "    return timelapse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_images(path, z_size = 6.0800000, x_y_size = 0.1700744):\n",
    "    \"\"\"\n",
    "    Load and rescale a DAPI fluorescence image stack (4D) to correct for anisotropy in Z-resolution.\n",
    "    This allows you to view the images with labels overlaid in Napari viewer\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Path to the input image file (assumed to be a 5D array: [T, C, Z, Y, X]).\n",
    "        The function extracts the first channel (e.g. DAPI) from the image.\n",
    "\n",
    "    z_size : float, optional\n",
    "        The physical step size in the z-direction (µm) of the image stack. Default is 6.08 µm.\n",
    "\n",
    "    x_y_size : float, optional\n",
    "        The physical pixel size in the x and y directions (µm). Default is 0.1700744 µm.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    rescaled_image : np.ndarray\n",
    "        A 4D array (T, Z, Y, X) where each frame has been rescaled to create isotropic voxel size.\n",
    "\n",
    "    Method:\n",
    "    -------\n",
    "    1. Load the full image and extract only the first channel (assumed to be DAPI).\n",
    "    2. Convert intensity range to 0–255 as `uint8`.\n",
    "    3. Compute the anisotropy factor based on physical Z vs. X/Y spacing.\n",
    "    4. Rescale Z/Y/X dimensions with a user-defined isotropy scaling factor (default 0.5).\n",
    "       Time dimension remains unchanged.\n",
    "    5. Return the rescaled image stack for viewing in napari.\n",
    "    \"\"\"\n",
    "    all_times_dapi = imread(path)[:,:,0,:,:]\n",
    "    image = convert(all_times_dapi, 0,255, np.uint8)\n",
    "    print(image.shape)\n",
    "    scale_change = scale_change = z_size / x_y_size #how much bigger the z step is than x,y\n",
    "    scale_value = 0.5\n",
    "    new_pixel_size = (1/scale_value) * x_y_size\n",
    "\n",
    "    #########CREATE LABELS\n",
    "    rescaled_image = rescale(scale = (1, scale_value*scale_change, scale_value, scale_value), image=(image ), anti_aliasing = False)\n",
    "    return rescaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "binary_root = \"C:\\\\Users\\\\itayl\\\\Downloads\\\\test_delete\\\\out\\\\combined\" # folder containing combined top+bottom binary segmentations\n",
    "binary_paths = list(pathlib.Path(binary_root).rglob(\"*.{}\".format(\"tif\")))\n",
    "combined_binary_root = \"C:\\\\Users\\\\itayl\\\\Downloads\\\\test_delete\\\\out\\\\stacked\"\n",
    "combined_label_root = \"C:\\\\Users\\\\itayl\\\\Downloads\\\\test_delete\\\\out\\\\unlinked_labels\"\n",
    "print(len(binary_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Binary Labkit Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_filenames = []\n",
    "for path in binary_paths:\n",
    "    filename = \"_\".join(os.path.basename(path).lower().split(\"_\")[2:])\n",
    "    if filename not in unique_filenames:\n",
    "        unique_filenames.append(filename)\n",
    "len(unique_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "for filename in unique_filenames:\n",
    "    z_slices = []\n",
    "    for path in binary_paths:\n",
    "        if filename in str(path).lower():\n",
    "            z_slices.append(path)\n",
    "    z_slices.sort()\n",
    "    all_images.append(z_slices)\n",
    "files = all_images\n",
    "sorted_files = natsort.natsorted(files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_images = []\n",
    "for image in all_images:\n",
    "    sorted_image = natsort.natsorted(image)\n",
    "    sorted_images.append(sorted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 11, 442, 456)\n",
      "(22, 12, 409, 409)\n"
     ]
    }
   ],
   "source": [
    "for image in sorted_images:\n",
    "    frames = []\n",
    "    for file in image:\n",
    "        filename = \"_\".join(os.path.basename(file).lower().split(\"_\")[2:]).split(\".tif\")[0]\n",
    "\n",
    "        img = imread(file)\n",
    "\n",
    "\n",
    "        frames.append(img)\n",
    "    timelapse_labels = np.stack(frames, axis=0)\n",
    "    print(timelapse_labels.shape)\n",
    "    output_path = combined_binary_root+\"\\\\{}_combined_timelapse.tif\".format(filename)\n",
    "    tifffile.imwrite(output_path, timelapse_labels, imagej=True, metadata={'axes': 'TZYX'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Binary Segmentations into Unlinked Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itayl\\Downloads\\test_delete\\out\\unlinked_labels\\24h-01-scene-04-p3_cropped_stiff_combined_timelapse_FILTEREDLABELS.tif\n",
      "C:\\Users\\itayl\\Downloads\\test_delete\\out\\unlinked_labels\\24h-01-scene-07-p9_cropped_stiff_combined_timelapse_FILTEREDLABELS.tif\n"
     ]
    }
   ],
   "source": [
    "combined_binary_images = list(pathlib.Path(combined_binary_root).rglob(\"*.{}\".format(\"tif\")))\n",
    "for image in combined_binary_images:\n",
    "    filename = \"_\".join(os.path.basename(image).lower().split(\"_\")[2:]).replace(\".tif\", \"\")\n",
    "    output_path = combined_label_root+\"\\\\{}_FILTEREDLABELS.tif\".format(filename)\n",
    "    print(output_path)\n",
    "    unlinked_labels = clean_labels(image)\n",
    "\n",
    "\n",
    "    tifffile.imwrite(output_path, unlinked_labels.astype(np.float32), imagej=True, metadata={'axes': 'TZYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels' at 0x28fde1d3c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(unlinked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move to FIJI/ImageJ to Create Linked Labels\n",
    "- If you have high temporal resolution you may be able to track in Python using TrackPy\n",
    "- However, Trackmate allows you to match between frames based on object morphology as well as location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
